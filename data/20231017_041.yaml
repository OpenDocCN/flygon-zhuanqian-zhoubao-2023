- qas:
  - 问题1：Fine-tuning 是什么意思？
  - 回答1：Fine-tuning 是指在预训练模型的基础上，使用特定的任务数据对模型进行重新训练，以适应具体的应用场景或任务。
  - 问题2：Embedding 的主要作用是什么？
  - 回答2：Embedding 是将高维的离散数据转化为低维连续向量表示的过程，用于捕捉单词之间的关联和语义相似性，从而使模型更好地理解和处理文本数据。
  - 问题3：为什么要对模型进行 Fine-tuning？
  - 回答3：Fine-tuning 可以使模型更加专业化，提高在具体任务上的准确性和效果，适应特定的任务需求。
  - 问题4：Fine-tuning 和 Embedding 的共同作用是什么？
  - 回答4：Fine-tuning 和 Embedding 可以共同帮助模型更好地适应特定任务，并提升模型在该任务上的表现。
  - 问题5：微调与学习准备考试的类比是什么意思？
  - 回答5：微调类比于通过长期学习准备考试，但在具体任务结束后，模型可能会逐渐忘记或误记一些没有频繁复习的内容。
  text: '# 从零开始：使用微调和嵌入训练自己的 AI 个性化大模型> 原文：[`www.yuque.com/for_lazy/thfiu8/cllfw39br1fqib3a`](https://www.yuque.com/for_lazy/thfiu8/cllfw39br1fqib3a)##
    (22 赞)从零开始：使用微调和嵌入训练自己的 AI 个性化大模型作者： 叫我峰兄日期：2023-10-10# 一.前言ChatGPT 是“大力出奇迹”的经典表现，大模型给
    ChatGPT 带来了惊人的智能，但是要训练这样的大模型，可是十分烧钱的，根据 OpenAI 给出的数据，1700 亿参数的 Davinci 模型从头训练一遍，大概需要耗时
    3 个月，耗资 150 万美元。那我们普通人或者小公司面对这个高门槛，对自定义模型是不是就完全没有希望了呢？其实除了从头训练一个模型，我们还可以选择基于一个基础模型进行训练，这样，我们可以往里添加自己的个性化数据，最终得到一个领域增强的个性化模型，目前有两种训练语料的方式
    embedding(嵌入)、Fine-tuning(微调)。个性化模型有什么用？我们知道，OpenAI 给的模型（如 Davinci、Curie、gpt3.5-turbo）都是通用化模型，而现代社会的行业和知识如此之庞大，每个领域都有自己细分的专业知识，比如，我们知道
    ChatGPT 的一个典型应用场景就是智能客服，但同样是客服，保险领域的客服和淘宝店铺的客服需要面对的客戶和需要解答的问题就完全不一样，想要给出更好的答案，我们就需要打磨自己的个性化模型。我们也可以用自己之前写的文章训练一个
    AI 版的自己，以个性化的口吻回复用户的问题。# 二.主流的训练模型的两种方式 Fine-tuning 和 Embedding## (一).概念介绍：1.  Fine-tuning（微调）：Fine-tuning
    是指在预训练模型的基础上，使用特定的任务数据对模型进行重新训练，以适应具体的应用场景或任务。通常，预训练模型通过大规模数据集进行事先训练，获得了广泛的语言理解和生成能力。而
    Fine-tuning 则是在此基础上，针对特定任务的数据集进行进一步训练，以使模型更好地适应该任务，并提高其性能。通过 Fine-tuning，可以使模型更加专业化，提高在具体任务上的准确性和效果。2.  Embedding（嵌入）：Embedding
    是将高维的离散数据转化为低维连续向量表示的过程。在自然语言处理中，Word Embedding 是一种常见的技术，将词汇表中的单词映射为实数向量。这些向量在低维空间中对应着单词的语义信息，使得计算机可以更好地理解和处理文本数据。通过将词汇嵌入到低维向量空间中，可以捕捉到单词之间的关联和语义相似性，从而使得模型能够更好地进行语言理解和相关任务。3.  在使用
    GPT 模型进行自然语言处理任务时，通常会先进行预训练得到一个通用的语言模型，然后根据具体的任务数据对模型进行 Fine-tuning，使其适应特定任务的需求。同时，模型将单词和文本嵌入到低维向量空间中，用于表示和处理文本数据，从而提高模型的语义理解能力和任务性能。Fine-tuning
    和 Embedding 可以共同帮助模型更好地适应特定任务，并提升模型在该任务上的表现。## （二）.Fine-tuning 和 Embedding 的区别1.  微调就像你通过学习准备考试，是一种长期记忆，但过了一周后考试来临，模型可能会忘记袭击，或者记错它从来没有读过的事实。'
- qas:
  - 问题1：嵌入是什么？
  - 回答1：嵌入就像记笔记，是一种短期记忆，当考试的时候，你把笔记带上，随时翻看笔记，对于笔记上有的内容可以得到准确的答案。
  - 问题2：嵌入的搜索提问方式有什么缺点？
  - 回答2：另外嵌入的搜索提问方式相对于微调有一个缺点就是它每次附带的文本数量是有限制的，因为除了原始的问题，它还需要带上搜索出来的问题，GPT-3.5 是 4K（大约
    5 页），GPT-4 最大是 32K（大约 40 页）。
  - 问题3：什么是搜索-问（Search-Ask）的方法？
  - 回答3：如果你想构建一个对大量文本问答的系统，OpenAI 建议“搜索-问”（Search-Ask）的方法，也就是先在本地文档库中 Search，拿到本地的数据结果，再去
    Ask，把搜索结果和问题一起交给 GPT，这样 GPT 可以根据你提供的内容以及它模型中的数据，一起将结果返还给你。
  - 问题4：如何比喻嵌入的搜索功能？
  - 回答4：就好比你有成书的教科书可以借鉴，但每次却只能翻看其中几页笔记。
  - 问题5：谁提出了搜索-问的方法？
  - 回答5：OpenAI 提出了搜索-问的方法。
  text: '2.  嵌入就像记笔记，是一种短期记忆，当考试的时候，你把笔记带上，随时翻看笔记，对于笔记上有的内容可以得到准确的答案。3.  另外嵌入的搜索提问方式相对于微调有一个缺点就是它每次附带的文本数量是有限制的，因为除了原始的问题，它还需要带上搜索出来的问题，GPT-3.5
    是 4K（大约 5 页），GPT-4 最大是 32K（大约 40 页）。4.  就好比你有成书的教科书可以借鉴，但每次却只能翻看其中几页笔记。5.  如果你想构建一个对大量文本问答的系统，OpenAI
    建议“搜索-问”（Search-Ask）的方法。6.  也就是先在本地文档库中 Search，拿到本地的数据结果，再去 Ask，把搜索结果和问题一起交给 GPT，这样
    GPT 可以根据你提供的内容以及它模型中的数据，一起将结果返还给你。为了更好的阅读体验，请前往飞书链接阅读：[`l0lupq5bcjq.feishu.cn/docx/DUOjdFQ6UoF3S3xppyvcYNzPnh6`](https://l0lupq5bcjq.feishu.cn/docx/DUOjdFQ6UoF3S3xppyvcYNzPnh6)*
    * *评论区：melisa : 棒Yuti : 好详细，解释的也比较明白叫我峰兄 : 感谢支持，有帮助就好[呲牙]乔帮主 : 很详细的整理，赞👍叫我峰兄 :
    帮主是我见过的为数不多的既懂技术又懂业务的大佬，从乔哥身上学到很多，我会继续努力，追赶乔哥的脚步[加油]叫我峰兄 : 感谢支持![](img/1c37d505930596d12a88ab23e11aa07a.png)*
    * *'
